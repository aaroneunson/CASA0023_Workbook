# Classification II

## Summary

### Landcover Classification (Continued)

[**Pre-classified Data Sources:**]{.underline}

-   GlobeLand30 provides 30m resolution data for 2000, 2010, and 2020.

-   ESA's Climate Change Initiative offers annual global land cover at 300m resolution from 1992-2015.

-   Dynamic World offers near real-time 10m resolution data.

-   Other sources include MODIS and Google's building data.

[**Dynamic World:**]{.underline}

-   Utilizes a semi-supervised approach with the world divided into three regions and 14 biomes.

-   Stratified samples are based on NASA's MCD12Q1 land cover data for 2017 among other sources.

-   Labeling involves both expert and non-expert groups, with a focus on achieving a balance in confidence levels across different classifications.

### Accuracy

[**Object-Based Image Analysis (OBIA):**]{.underline}

-   Focuses on representing ground objects as shapes (superpixels) based on their homogeneity or heterogeneity.

-   The SLIC algorithm is a common method for superpixel generation, balancing between physical distance and color similarity.

[**Sub-Pixel Analysis:**]{.underline}

-   Addresses the issue of pixels composed of multiple land cover types by determining the proportion of each land cover within a pixel.

[**Accuracy Assessment:**]{.underline}

-   Involves assigning an accuracy value to the output of remote sensing analysis, focusing on Producer's Accuracy, User's Accuracy, and Overall Accuracy.

-   The Kappa Coefficient and F1 Score are among the metrics used to evaluate accuracy, with considerations for the balance between recall and precision.

-   The Receiver Operating Characteristic (ROC) Curve and Area Under the ROC Curve (AUC) are used to assess the performance of binary classifiers.

[**Spatial Considerations in Accuracy Assessment:**]{.underline}

-   Spatial cross-validation and the consideration of spatial autocorrelation are highlighted as important factors in ensuring the reliability of classification models.

-   The need for spatially aware methods like spatial leave-one-out cross-validation (SLOO CV) and k-fold cross-validation with spatial partitioning is emphasized.

## Application

### A Deep Convolution Neural Network Method for Land Cover Mapping

**A Case Study of Qinhuangdao, China**

[Hu et al (2018)](https://www.mdpi.com/2072-4292/10/12/2053) address several challenges in land cover classification using traditional CNN methods, such as the application to multispectral and hyperspectral imagery and the automation of training dataset construction. They introduce a novel deep CNN (DCNN) based on Landsat-8 imagery, which integrates cascaded cross-channel parametric pooling and global average pooling methods. Their adapted approach allowed the researchers to well utilise multispectral data from the Landsat-8 OLI. This approach is directly responding to the need for models that are able to better generalise and handle the complex nature of satellite imagery, including the challenge of automating the construction of a training database.

The study introduces a semi-automatic method for constructing these datasets, which significantly reduces the need for manual labour (such as manually labelling training data - a long, slow, and arduous task!). It leverages existing high-quality land cover products (such as comprehensive maps or datasets that have already been accurately classified). By extracting land type information from these products, the method can automatically assign labels to training data points based on their location and the corresponding classification in the high-quality land cover product.

> For example, if a satellite image pixel falls within a region classified as "forest" in a high-quality land cover map, the semi-automatic method can automatically label that pixel as "forest" in the training dataset. This approach allows for the creation of large, accurately labeled training datasets at a greater pace than other methods, enabling more efficient training of DCNNs for tasks like land cover classification.

This addresses a major bottleneck in applying machine learning to remote sensing, which is the task of preparing large-scale, accurately labelled datasets. By automating part of the labeling process, researchers can more readily apply advanced machine learning models to the vast amounts of satellite imagery available, potentially leading to better models for predicting and understanding land cover changes on a global scale.

The DCNN model demonstrated superior performance over traditional methods, achieving an overall accuracy of 82.0% and a kappa coefficient of 0.76. This improvement is attributed to the model's ability to incorporate spatial information from surrounding pixels (vital for addressing spatial autocorrelation which is inherent in spatial data), reducing misclassifications that often occur in pixel-based approaches. Typical pixel-based approaches might treat each pixel as independent, ignoring the potentially valuable context provided by adjacent pixels. The DCNN employed here is able to accurately distinguish between land uses (such as in areas where the boundaries between different land covers are more graduated or where classes have similar spectral signatures but are spatially distinct). The overall accuracy value and kappa coefficient highlight the significant improvements that can be attained through deep learning models when compared with other classification methods such as SVM and MLC.

## Reflection

As discussed last week, ML takes quite a central themes of this week and indeed is a very big and exciting subject within classification. The case study of Qinhuangdao demonstrates the improvements that can be achieved when employing unsupervised techniques and when also accounting for inherent methodological issues. It is only semi-supervised though (rather than fully unsupervised), with it utilising an unsupervised method of classifying pixels, through existing datasets trained under supervision.

Something that I have noticed though is that I see the lectures and the methods being taught within these (e.g. sub-pixel analysis or CNN). During these, the methods seems somewhat straightforward (although a constant theme is the complexity involved in many aspects of RS). But then when I research, it becomes clear that there is an extensive array of variations, interpretations and adaptations of the methods. Initially, this struck me as daunting - how could I ever learn all of these and make sense of them. But through reading some more, it is evident that there are general principles which are constantly regarded. For example, variations of a method may simply involve changing threshold levels or minor process tweaks. Instead it is actually exciting - that there is so much interest and such burgeoning adaptability, demonstrates the will that researchers posses to explore new possibilities and identify more accurate, precises and efficient methods. It demonstrates that the RS community still has much to discover, learn and discuss.
